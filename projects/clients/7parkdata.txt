
data collection audit table
data collection change history table

part 2: scheduling of dropoff of data

===============
create table dd_artifact(
	id int not null auto_increment primary key,
	name varchar(255)
);

create table dd_datastore(
	id int not null auto_increment primary key,
  platform varchar(255)
	name varchar(255),
  location varchar(500)
);

create table dd_datacatalog(
  id int not null auto_increment primary key,
  dataset_id int,
  artifact_id int,
  datastore_id int,
  FOREIGN KEY (dataset_id) REFERENCES distrodb.rptlob(id),
  FOREIGN KEY (artifact_id) REFERENCES distrodb.dd_artifact(id),
  FOREIGN KEY (datastore_id) REFERENCES distrodb.dd_datastore(id)
);

drop table dd_datacatalog;
drop table dd_artifact;
drop table dd_datastore;
create table dd_datacatalog(
  id int not null auto_increment primary key,
  product_line varchar(250),
  dataset varchar(250),
  artifact varchar(255),
  platform varchar(255),
  env_or_bucket varchar(255),
  location varchar(500)
);

create table dd_client(
  id int not null auto_increment primary key,
  name varchar(1000),
  salesforce_account_id varchar(500) unique,
  primary_contact_id varchar(500),
  primary_contact_name varchar(1000)
);

create table dd_datadelivery(
  id int not null auto_increment primary key,
  client_id int,
  datacatalog_id int,
  start_date datetime,
  end_date datetime,
  delivery_location varchar(1000),
  FOREIGN KEY (client_id) REFERENCES distrodb.dd_client(id),
  FOREIGN KEY (datacatalog_id) REFERENCES distrodb.dd_datacatalog(id)
);

ALTER TABLE reporttemplate ADD schedule VARCHAR(500) after name

kibana
  https://search-sendgridevents-6fwo5scolykj3xpbfg7m476tk4.us-east-1.es.amazonaws.com/_plugin/kibana/?#/discover?_g=(refreshInterval:(display:Off,section:0,value:0),time:(from:now-90d,mode:quick,to:now))&_a=(columns:!(reportsubject,email,event),index:'cwl-*',interval:auto,query:(query_string:(analyze_wildcard:!t,query:'reportinstanceid:%205662%20AND%20event:%20click')),sort:!('@timestamp',desc)) 
  https://search-sendgridevents-6fwo5scolykj3xpbfg7m476tk4.us-east-1.es.amazonaws.com/_plugin/kibana/?#/discover?_g=(refreshInterval:(display:Off,section:0,value:0),time:(from:now-7d,mode:quick,to:now))&_a=(columns:!(reportsubject,email,event),index:%27cwl-*%27,interval:auto,query:(query_string:(analyze_wildcard:!t,query:%27*%27)),sort:!(%27@timestamp%27,desc))

prod server
====
http://reporting.7parkdata.com/ (http://54.82.204.54:8080/)
ssh 7parkdata
ps aux | grep -i python
vim /tmp/supervisord.log

run (local)
====
export PROD_CONFIG=/Users/joegallo/dev/7parkdata/distro/distrib/settings_prod.py (optional)
unset PROD_CONFIG
echo $PROD_CONFIG
python distrib/app.py

release process
====
merge develop into master
push changes to master

test client emails
====
http://127.0.0.1:8080/editInstance?instanceId=797

test addPostToTimeline
====
http://127.0.0.1:8080/editInstance?instanceId=781  # no writeup
http://127.0.0.1:8080/editInstance?instanceId=778  # writeup
http http://avenue-api.7parkdata.com/v2/timeline/posts "Authorization:Token 452ae83a7c4cae52afb40cb1ce5254def5a1e19b"

test edit report definition
====
http://localhost:8080/editReport?reportId=37

3 main groups of tables
====
non-prefixed (app config, etc.)
rb_: (report builder)
report/rpt

caveats
====
reportinstance.report_id is instance id (report__id is report id)
reportdefinitions.report_id is report definition id

hours
====
12/13/16: [] ()
  * 
